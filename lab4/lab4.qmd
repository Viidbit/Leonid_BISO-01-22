---
title: "Исследование метаданных DNS трафика"
subtitle: "Практика №3"
author: "Lona610@yandex.ru"
format: 
  md:
    output-file: README.md
---



## Цель работы

1.  Зекрепить практические навыки использования языка программирования R
    для обработки данных
2.  Закрепить знания основных функций обработки данных экосистемы
    tidyverse языка R
3.  Закрепить навыки исследования метаданных DNS трафика

## Исходные данные

1.  Программное обеспечение ОС Windows 11
2.  VS Code
3.  Интерпретатор языка R 4.5.1

## Задания

1.  Импортируйте данные DNS –
    https://storage.yandexcloud.net/dataset.ctfsec/dns.zip Данные были
    собраны с помощью сетевого анализатора zeek
2.  Добавьте пропущенные данные о структуре данных (назначении столбцов)
3.  Преобразуйте данные в столбцах в нужный формат,просмотрите общую
    структуру данных с помощью функции glimpse()
4.  Сколько участников информационного обмена всети Доброй Организации?
5.  Какое соотношение участников обмена внутрисети и участников
    обращений к внешним ресурсам?
6.  Найдите топ-10 участников сети, проявляющих наибольшую сетевую
    активность.
7.  Найдите топ-10 доменов, к которым обращаются пользователи сети и
    соответственное количество обращений
8.  Опеределите базовые статистические характеристики (функция summary()
    ) интервала времени между последовательными обращениями к топ-10
    доменам.
9.  Часто вредоносное программное обеспечение использует DNS канал в
    качестве канала управления, периодически отправляя запросы на
    подконтрольный злоумышленникам DNS сервер. По периодическим запросам
    на один и тот же домен можно выявить скрытый DNS канал. Есть ли
    такие IP адреса в исследуемом датасете?
10. Определите местоположение (страну, город) и организацию-провайдера
    для топ-10 доменов. Для этого можно использовать сторонние
    сервисы,например http://ip-api.com (API-эндпоинт –
    http://ip-api.com/json).

## Шаги:

1 Импортируйте данные DNS

``` {r}
library(tidyverse)
```



``` {r}

library(tidyverse)
library(lubridate)
library(httr)
library(jsonlite)
library(readr)
dns_data <- read_tsv("dns.log", col_names = FALSE, comment = "#", show_col_types = FALSE)
```

 
2 Добавьте пропущенные данные о структуре данных (назначении столбцов) 



``` {r}

colnames(dns_data) <- c("ts", "uid", "id_orig_h", "id_orig_p", "id_resp_h", 
                        "id_resp_p", "proto", "trans_id", "query", "qclass", 
                        "qtype", "rcode", "rcode_name", "AA", "TC", "RD", 
                        "RA", "Z", "answers", "TTLs", "rejected")
if(ncol(dns_data) > 21) {
  dns_data <- dns_data[, 1:21]
}
```

3 Преобразуйте данные в столбцах в нужный формат

``` {r}
dns_data_clean <- dns_data %>%
  mutate(
    timestamp = as.POSIXct(timestamp, origin = "1970-01-01"),
    source_port = as.numeric(source_port),
    destination_port = as.numeric(destination_port),
    transaction_id = as.numeric(transaction_id),
    qclass = as.numeric(qclass),
    qtype = as.numeric(qtype),
    rcode = as.numeric(rcode),
  ) %>% as_tibble()

head(dns_data_clean,10)
```

4 Просмотрите общую структуру данных с помощью функции glimpse()

``` {r}
glimpse(dns_data)
```


5 Сколько участников информационного обмена в сети Доброй Организации?

``` {r}
unique_ips <- unique(c(dns_data$id_orig_h, dns_data$id_resp_h))
cat("\nУчастников обмена:", length(unique_ips), "\n")
```




6 Какое соотношение участников обмена внутри сети и участников обращений
к внешним ресурсам?

``` {r}
internal_ips <- dns_data %>%
  filter(str_detect(id_orig_h, "^(10\\.|172\\.(1[6-9]|2[0-9]|3[0-1])\\.|192\\.168\\.)")) %>%
  distinct(id_orig_h) %>%
  nrow()

external_count <- length(unique_ips) - internal_ips
cat("Соотношение внутренних и внешних участников:", internal_ips, "/", external_count, "\n")
```

7 Найдите топ-10 участников сети, проявляющих наибольшую сетевую
активность.

``` {r}
top_active <- dns_data %>%
  count(id_orig_h, sort = TRUE) %>%
  head(10)
cat("\nТоп активных участников:\n")
```


 

``` {r}
print(top_active)
```



8 Найдите топ-10 доменов, к которым обращаются пользователи сети и
соответственное количество обращений

``` {r}
top_domains <- dns_data %>%
  count(query, sort = TRUE) %>%
  head(10)
cat("\nТоп доменов:\n")
```


    Топ доменов:

``` {r}
print(top_domains)
```



9 Опеределите базовые статистические характеристики (функция summary())
интервала времени между последовательными обращениями к топ-10 доменам

``` {r}
top_domain_stats <- dns_data %>%
  filter(query %in% top_domains$query) %>%
  arrange(query, ts) %>%
  group_by(query) %>%
  mutate(time_diff = as.numeric(ts - lag(ts), units = "secs")) %>%
  summarise(
    min = min(time_diff, na.rm = TRUE),
    q1 = quantile(time_diff, 0.25, na.rm = TRUE),
    median = median(time_diff, na.rm = TRUE),
    mean = mean(time_diff, na.rm = TRUE),
    q3 = quantile(time_diff, 0.75, na.rm = TRUE),
    max = max(time_diff, na.rm = TRUE),
    .groups = 'drop'
  )

print(top_domain_stats)
```


10 Часто вредоносное программное обеспечение использует DNS канал в
качестве канала управления, периодически отправляя запросы на
подконтрольный злоумышленникам DNS сервер. По периодическим запросам на
один и тот же домен можно выявить скрытый DNS канал. Есть ли такие IP
адреса в исследуемом датасете?

``` {r}
suspicious_activity <- dns_data %>%
  count(id_orig_h, query, sort = TRUE) %>%
  filter(n > 5) %>%
  head(10)

if(nrow(suspicious_activity) > 0) {
  cat("Подозрительные IP с повторяющимися запросами:\n")
  print(suspicious_activity)
} else {
  cat("Нет подозрительной активности\n")
}
```


## Оценка результата

В результате практической работы мы поняли как анализировать данные DNS
с помощью языка R.

## Вывод

Таким образом, мы научились, используя язык r, скачивать и анализировать
данные DNS.



